{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from src.metrics import mapk, transform_y\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_pickle('generated_files/120K/train_X.pkl')\n",
    "train_Y = pd.read_pickle('generated_files/120K/train_Y.pkl')\n",
    "\n",
    "test_X = pd.read_pickle('generated_files/120K/test_X.pkl')\n",
    "test_Y = pd.read_pickle('generated_files/120K/test_Y.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_features = [col for col in train_X.columns if 'FT_' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_with_timeseries_features(X):\n",
    "    X_pred = X[prediction_features]\n",
    "\n",
    "    how_long_had = X_pred.groupby(X['Customer_Code']).cumsum()\n",
    "    ever_had = how_long_had > 0\n",
    "    had_and_does_not_have_now = ever_had & ~(X_pred.astype('bool'))\n",
    "\n",
    "    for ft in prediction_features:\n",
    "        X['HAD_NOT_NOW_' + ft] = had_and_does_not_have_now[ft].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhance_with_timeseries_features(train_X)\n",
    "enhance_with_timeseries_features(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_train(train_X, train_Y):\n",
    "    is_changed_series = train_Y.sum(axis=1) > 0\n",
    "    \n",
    "    X_reduced = train_X[is_changed_series].reset_index(drop=True)\n",
    "    Y_reduced = train_Y[is_changed_series].reset_index(drop=True)\n",
    "    \n",
    "    return X_reduced, Y_reduced\n",
    "\n",
    "X_tr_reduced, Y_tr_reduced = reduce_train(train_X, train_Y)\n",
    "X_ts_reduced, Y_ts_reduced = reduce_train(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.province import get_province_data\n",
    "\n",
    "province_df = get_province_data()\n",
    "\n",
    "def prepare_xgb_data(X):\n",
    "    xgb_X = X.drop(['Row_Date', 'Customer_Code'], axis=1)\n",
    "    \n",
    "#     formated_province = xgb_X['Province_Name'].str.replace(\",.*$\",\"\")\n",
    "#     xgb_X['Province_GDP'] = formated_province.apply(lambda s: province_df.loc[s]['gdp']).astype('float64')\n",
    "#     xgb_X['Province_Density'] = formated_province.apply(lambda s: province_df.loc[s]['density']).astype('float64')\n",
    "    \n",
    "    xgb_X['Province_Name'] = xgb_X['Province_Name'].apply(lambda s: 1 if s == 'MADRID' else 0).astype('float64')\n",
    "    xgb_X['Sex'] = xgb_X['Sex'].apply(lambda s: 1 if s == 'V' else 0).astype('float64')\n",
    "    xgb_X['Segmentation'] = xgb_X['Segmentation'].apply(lambda s: 1 if 'TOP' in s else 0 if 'PARTICULARES' in s else -1).astype('float64')\n",
    "    \n",
    "    return xgb_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_row(y_row, x_row, n_labels, thresh):\n",
    "    row = y_row * (~x_row.astype('bool'))\n",
    "    res = np.argsort(-row)[:n_labels]\n",
    "    res = res[row[res] >= thresh]\n",
    "    return res\n",
    "\n",
    "def predict_order(probas, X):\n",
    "    return [predict_row(y_row, x_row, 7, 0.0001) for y_row, x_row in zip(probas, X[prediction_features].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_X_tr = prepare_xgb_data(X_tr_reduced)\n",
    "xgb_X_ts = prepare_xgb_data(X_ts_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                            colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=1, gamma=0,\n",
       "                                            learning_rate=0.1, max_delta_step=0,\n",
       "                                            max_depth=6, min_child_weight=1,\n",
       "                                            missing=None, n_estimators=100,\n",
       "                                            n_jobs=1, nthread=None,\n",
       "                                            objective='binary:logistic',\n",
       "                                            random_state=0, reg_alpha=0,\n",
       "                                            reg_lambda=1, scale_pos_weight=1,\n",
       "                                            seed=None, silent=None, subsample=1,\n",
       "                                            tree_method='hist', verbosity=1),\n",
       "                    n_jobs=-1)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OneVsRestClassifier(n_jobs=-1, estimator=xgboost.XGBClassifier(tree_method='hist', max_depth=6))\n",
    "model.fit(xgb_X_tr, X_tr_reduced[prediction_features] + Y_tr_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8473047617906742"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas = model.predict_proba(xgb_X_ts)\n",
    "try_order = predict_order(probas, xgb_X_ts)\n",
    "mapk(transform_y(Y_ts_reduced, thresh=0.01), try_order, k=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8748325819479665"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_last_month = X_ts_reduced['Row_Date'] == '2016-04-28'\n",
    "xgb_X_ts_last = prepare_xgb_data(X_ts_reduced[test_last_month])\n",
    "Y_ts_last = Y_ts_reduced[test_last_month]\n",
    "\n",
    "probas = model.predict_proba(xgb_X_ts_last)\n",
    "try_order = predict_order(probas, xgb_X_ts_last)\n",
    "mapk(transform_y(Y_ts_last, thresh=0.01), try_order, k=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
